---
layout: home
title: Stuart's PGCert Portfolio
---
- [Introduction](#introduction)
- [Reflective Area 1 – Operational Issues](#reflective-area-1--operational-issues)
- [Reflective Area 2 – Learning, Teaching and Assessment](#reflective-area-2--learning-teaching-and-assessment)
- [Reflective Area 3 – Wider Context](#reflective-area-3--wider-context)
- [Reflective Area 4 – Specialist Interest](#reflective-area-4--specialist-interest)
- [Professional Development Planning](#professional-development-planning)
- [Conclusion](#conclusion)
- [Bibliography](#bibliography)

## Introduction

My name is Stuart Smith, and I work as the Digital Skills Developer at the University of Greenwich—a unique role that focuses on how students engage with digital technologies both during their studies and in preparation for their future careers. This role builds on earlier work I’ve done in learning technology in both commercial and university settings.

Technology isn’t something I add into my work—it’s woven into it. From the Microsoft 365 suite to tools like Visual Studio Code, Adobe Creative Cloud, and even my experiments with JavaScript and Python, I aim to model the kind of thoughtful digital practices I want students to develop. With the rise of generative AI, tools like Copilot have become central to my work. I see them as transformative—not just in terms of automation, but in terms of how we think, create, and support learners. I believe strongly in using the same tools I introduce to students, and I see my role as a guide helping them navigate this fast-evolving landscape.

[↑ Back to top](#introduction)

## Reflective Area 1 – Operational Issues

A core part of my practice involves integrating tools like Copilot, Microsoft Teams, and Visual Studio Code into everyday learning support. I use Copilot regularly, especially in workshop scenarios. For example, when I was running an Excel tutorial and discovered that key learning materials had been deprecated, I used Copilot in real-time to generate a new learning activity based on prompts that students helped craft. This turned what could’ve been a failure into a moment of digital empowerment. Students saw that a lack of knowledge wasn't a dead end—it was a prompt for collaboration, experimentation, and co-creation.

Copilot excels in many areas—particularly as a personal tutor or coach. Its ability to understand natural language, propose ideas, and reframe problems makes it particularly useful for students with lower confidence or those from non-traditional learning backgrounds. But it’s not without constraints. Enterprise-level censorship, hallucinations, and limited philosophical depth can frustrate more advanced users. In terms of ethical use, Copilot’s cheerful tone sometimes masks a lack of clarity about its boundaries, and it can become evasive when questioned about deeper topics.

Similarly, I use Visual Studio Code for more technical work—particularly for its support of Markdown and Jupyter notebooks. Markdown is one of the oldest and most robust text formats available and has particular value in education because of its accessibility, structure, and long-term archival viability. Unfortunately, Microsoft’s broader ecosystem isn’t Markdown-friendly. Word and Teams, for instance, don't offer clean Markdown workflows, which can present real limitations when working with screen readers or preparing structured content for future reuse.

[↑ Back to top](#introduction)

## Reflective Area 2 – Learning, Teaching and Assessment

All of my teaching takes place online, primarily through Microsoft Teams. I’ve adapted my sessions to be fully interactive, even when students don’t turn on their cameras. Tools like MentiMeter and Microsoft Forms allow me to create moments of live feedback and insight. These tools help students who might otherwise be silent in a traditional classroom feel seen and heard. Menti’s anonymity, in particular, is powerful—it gives students permission to admit they don’t know something, or to experiment with an idea they aren’t confident in yet.

Copilot has become foundational to my teaching strategy. In an Excel session, for example, students were able to use Copilot to create custom tutorials based on their own goals and questions. This not only increased relevance but showed students how to take ownership of their learning journey. Similarly, when demonstrating Word’s Editor feature, many were surprised to learn they already had access to such sophisticated support for grammar, style, and structure—features that are particularly empowering for those with lower academic English levels or dyslexia.

I’ve also noticed that TEL can be a double-edged sword. The lack of student cameras can make teaching online feel isolating, and bandwidth limitations or noisy environments mean many students attend from less-than-ideal locations. However, by incorporating chat-based interaction, flexible feedback loops, and design that anticipates these limitations, we still create valuable experiences.

Inclusion remains a priority. Many of our students are multilingual, and some have experienced educational trauma. When one mature student, previously bullied in her workplace over digital skills, realised she could use Copilot to reframe complex information in her own words, she cried with relief. That moment reminded me of the profound emotional and psychological role TEL can play in helping people reclaim their agency.

[↑ Back to top](#introduction)

## Reflective Area 3 – Wider Context

Accessibility and data ethics are foundational concerns in my work. My MSc dissertation focused on interface design for learners with specific needs, and since then I’ve contributed to JISC and government advisory panels on accessibility. But accessibility is more than just screen reader compliance. It’s about recognising that students arrive with diverse needs—linguistic, cultural, neurodivergent—and that inclusive design starts with listening.

I champion open formats like Markdown because they promote accessibility through structure and transparency. Unlike proprietary file formats, Markdown works cleanly with assistive technologies and ensures content can be archived or shared without requiring expensive or restrictive platforms.

Ethically, we face difficult questions around AI. Should students be allowed to write essays in their first language and use AI to translate into English? Current policy says no—but we admit students knowing they don’t yet have academic English proficiency. If we're not willing to allow AI-assisted translation, are we also willing to ban private tutoring, which creates far greater inequality? These are the kinds of dilemmas we need to address honestly and empathetically.

On data privacy: institutional systems often don’t talk to each other. Staff end up replicating student data in insecure ways—OneDrive folders, spreadsheets, emails. Students mimic this without understanding the implications. I teach students that managing information isn’t about hoarding—it’s about stewardship. Know where your data is, why it's there, and who can see it.

[↑ Back to top](#introduction)

## Reflective Area 4 – Specialist Interest

My core area of specialist interest is the intersection of generative AI, immersive environments, and personalised learning. I’m especially drawn to open-source AI models that can run locally and be combined with Retrieval-Augmented Generation (RAG) frameworks. With these tools, we can let students interrogate large sets of course data, reading lists, and materials using natural language—in their own voice and at their own pace.

I see huge potential for building learning companions that aren’t just reactive but contextual. Imagine a student in an immersive VR space, moving through course content visually, spatially, and interactively—asking questions, testing ideas, and receiving tailored responses from a localised, privacy-respecting AI tutor. It’s an ambitious vision, but one that feels like the natural evolution of TEL.

I'm also concerned about the lack of open standards. While tools like Copilot are powerful, their opacity and corporate ties limit their educational potential. We need transparent, accountable AI systems if we want to support academic freedom and innovation. I believe in technology as a democratising force—but only if it remains open, ethical, and student-focused.

[↑ Back to top](#introduction)

## Professional Development Planning

My next formal step is applying for CMALT, which I see as a way to consolidate and articulate the TEL journey I’m already on. I’m fortunate to work alongside several Certified Members of ALT, and I look forward to joining that professional community.

Longer term, I’d like to explore collaborative research around generative AI in education, including projects like the Digital Backpack—our digital capability assessment and credentialing tool. I also want to improve my programming fluency so I can prototype some of the learning tools I imagine. Right now, Copilot itself is helping me do that, guiding me through Python and JavaScript as I experiment.

Eventually, I’d like to contribute more actively to the field through publications and collaborative tool-building. I’m even considering a PhD, though I’m more focused in the short term on meaningful, hands-on development that empowers students and reimagines what assessment and learning could be.


[↑ Back to top](#introduction)

## Conclusion

Before beginning this PGCert, I didn’t value reflection as much as I do now. Having a scaffolded portfolio has helped me see its importance—not just for academic growth, but for refining my own thinking. I plan to continue this habit well beyond the PGCert, using tools like Jekyll and Markdown to build a sustainable, portable professional portfolio.

This process has reinforced many of my core beliefs: that digital tools can democratise learning, that students need agency, and that institutions must do better in protecting and empowering learners. It’s also deepened my interest in systemic innovation—from immersive learning to ethical AI, from accessibility to data minimalism.

I’ve come away from this with a stronger sense of direction and a renewed belief that, while technology often introduces new challenges, it also opens doors for creativity, access, and transformation—especially when guided by thoughtful educators.

[↑ Back to top](#introduction)

## Bibliography

To be added.

<!-- - Brown, T. (2022). *Inclusive Online Engagement: Practices for the Digital Classroom*. EdTech Press.
- Jones, M. (2018). *Rethinking Student Reflection: Platforms for Ownership and Engagement*. Journal of TEL, 14(2), pp. 1–15.
- Microsoft. (2023). *Copilot for Microsoft 365: Enterprise Overview*. Retrieved from https://www.microsoft.com
- Microsoft. (2024). *AI Design and Accessibility in Office Tools*. Microsoft Learn.
- Okpara, C. (2021). *Designing for Accessibility in Digital Learning Environments*. Open Access TEL Review, 9(4), pp. 33–47.
- OpenAI. (2024). *Understanding Large Language Models: Transparency and Trust*. Retrieved from https://www.openai.com
- Smith, J. (2019). *Digital Natives and Assessment Design*. Higher Education Futures, 12(3), pp. 44–60.
[↑ Back to top](#introduction)-->